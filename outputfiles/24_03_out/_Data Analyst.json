{"text": "Name: gertrude gertrude E-Mail: gertrude.gertrude@gmail.com Address: Lu\u2019an, China Github: https://github.com/gertrude LinkedIn: https://linkedin.com/gertrude Phone No. 12407339777 Summary  Around 4 years of experience in the field of Information Technology with solid experience in Data Analysis ,Business Analysis, Design and Development. Involved in providing production support to various Data Warehousing, Data Integration, in ETL source to target mapping.  Using Facets for various health insurance areas such as enrollment, member, Products and other FACETS related modules Experience working on 5010 HIPAA implementation guides relate to Claim Testing and Medical Billing. Strong understanding of various SDLC methodologies such as RUP, Waterfall and Agile with hands on experience in all of them Knowledge of the EDI transaction sets such as 837, 834, 835, 270, 271, 276, 277, 999 Understanding of HIPAA Standards and Compliance issues, HIPAA Privacy policy, opt in/opt out policy. Experience in working in both Windows, Linux and UNIX platforms including programming and debugging skills in UNIX Shell Scripting. Developed Test Cases, Test Scripts and SQL to perform Unit Testing, System Testing and Load Testing. Worked with Operations and Platform teams to migrate ETL Code and DB objects from Development to Testing, UAT and Production. Experience in working with various data sources like Sequential file, Oracle, SQL Server, Teradata and Flat Files in Datastage designer.  Extensive experience with Data Warehousing, Extraction, Transformation and Loading (ETL) and Business Intelligence (BI) tools. Hands on experience in all major facets of Project management \u2013 project planning, execution, milestone monitoring, resource utilization and driving a team with multi vendors and customer. Executed SQL queries and documented them as part of validating the Business Object reports  and for testing purposes\u00a0 Experience in creating SQL queries to facilitate UAT and perform data validation. Experience in methodologies like Agile, Waterfall Model and Data Modeling; Creating Process mapping, Use Cases, Sequence diagrams, Activity diagrams Excellent experience in troubleshooting test scripts, SQL queries, ETL jobs, data warehouse/data mart/data store models. Solid understanding of Membership, Claims Processing, Billing, Benefit/Eligibility, Authorization/Referrals, COB, and have experience in HIPAA standards and corresponding EDI transactions. Detail oriented and strong project management skills coupled with excellent knowledge of SDLC, Agile Processes and SCRUM. Strong Knowledge of Hadoop Ecosystem (HDFS, HBase, Scala, Hive, Pig, Flume, NoSQL etc.) and Data modelling in Hadoop environment. Facets support systems were used to enable inbound/outbound HIPAA EDI transaction in support of HIPAA 834, 835, 837 270/271 transactions. Proficient in conducting System Testing, Functionality Testing, Regression Testing, User Acceptance Testing (UAT) and training of users Involved in maintaining Test Matrix and Traceability Matrix and performing GAP analysis Experience in\u00a0Data\u00a0Mining,\u00a0Data\u00a0mapping and Data modeling and good understanding of the ETL tools like AB Initio, SSIS and Informatica Power Center. Technical Skills: Database Tools\t SQL Plus, SQL Loader, SQL Developer, TOAD, Serena Testing Tools:\tTeradata, ETL, Data Stage/Quality Stage, SAS Data Flux Informatics Data Quality,  Programming Languages         \tSQL, PL/SQL, UNIX Business Intelligence shell Scripting, VBScript, PERL, AWK, SED Reporting Tools:\tTableu, Cognos, Microstrategy, Report Builder Reporting Services (SSRS)  Databases:   \tOracle, SQL Server, DB2 UDB 8.x/7.x Operating Systems:                       Windows /XPDOS, UNIX, Linux RDBMS:\tSQL, Oracle, and MS Access Scrum Master                                Agile Project Manager, UML, Visio, RUP, Waterfall Utilities/Application:\tMS Project, MS Visual, MS Office 03/07 (MS- Access, MS-Outlook), MS-PowerPoint Word MS-Excel, MS-  Professional Experience Centene Corporation, St. Louis, MO                                                                                  Feb 2018\u2013 Nov 2019   Data Analyst    The project scoped for receiving, documenting, processing the claims including the eligibility verification. The team was responsible for making the system changes accordingly the changes need to be made in the current policies, rules & regulations due to the business requirements. My role in this project was to develop the application that ensured automatic data uploading, hourly data refreshing, automatic confirmation of the data for the online billing application. I also maintained their online billing web pages. Roles & Responsibilities: Wrote advanced SQL queries to extract, manipulate, and/or calculate information to fulfill data and reporting requirements including identifying the tables and columns from which data is extracted.  Worked as a Data Analyst to translate customer product requirements into comprehensive, complete and accurate business requirements and functional specification. Responsible for Data modeling and Mapping through data analysis to extract data elements from various OLTP\u2019s using ETL technique and utilized Business Intelligence Tool for report generation. Used Data warehousing for Data Profiling to examine the data available (Data Analysis) in an existing database. Involved in MDM Process including data modeling, ETL process, and prepared data mapping documents based on graph requirements.\u00a0 Documented all the issues regarding Data Integrity. Used UML for Business Modeling for drawing the corresponding modeling diagram such as Use Case, Activity, Sequence, and Collaboration Diagrams. Analyzed, Revised and Created Test Plans according to business requirements. Involved in Data modeling using Informatica IDQ and MS Visio. Heavily involved in interacting with UNIX Shell scripts. Experience in Advanced modeling and calculations using Microsoft Power BI. Worked with VBA Macros with Excel VBA, which automate tasks in Excel by writing macros. Developed the VBA Integration with Excel feeds and SQL database, SQL Extraction, Transformations of Excel Data into SQL database. Scheduled execution of procedures using Unix Shell Scripts for updating of tables. Provided support to Data Architect and Data Modeler in Designing and Implementing Databases for MDM using ERWIN Data Modeler Tool and MS Access.  Successfully designed logical and physical database models using Informatica IDQ, data modeler; designed initial database migration plans and procedures for migrating data. Developed reports and dashboards using Microsoft Power BI stack - Power Pivot, power query. Created Stored Procedures, User-Defined Functions, Ad-hoc Scripts and Cursors on Development and Test servers for pre-deployment testing.  Performing Data Quality Checks and cleansing the incoming data feeds as and profiling the source systems data as per business rules using IDQ  Maintained and monitored project progress and status through MS Project. Used SQL tools like TOAD to run SQL queries to view and validate the data loaded into the warehouse. Did data profiling using Informatica IDQ. Data mining, data mapping, data cleansing. Worked closely with the Enterprise Data Warehouse team and Business Intelligence. Performed extensive task which include Data Quality Analysis, Data lineage and Data Standardization data structures, data base design, data warehouses, business. Used intelligence/analytic tools, SQL, ETL tools, and data integration methods Using Microsoft Power BI and Power Query to extract data from external sources and modify data to certain format as required. Building custom cleanse functions using IDQ for\u00a0Informatica\u00a0Data Analyst IDA to take data cleansing to the next level.\u00a0 Developed\u00a0SAS macros\u00a0for Data cleaning, Data mining and Reporting. Data mapping, logical data modeling, used SQL queries to filter data within the Oracle. Anthem, Virginia Beach, VA                                                                                               Jan 2016-Jan 2018   Data Analyst                                                      Anthem brought a new Automation process in their Provider Data Exchange team. This was a PEGA application build to make things easier, reliable and to cut the manual manpower. Responsible for doing the Data analysis for migration of data from legacy system to new system. Roles & Responsibilities: Wrote advanced SQL queries to extract, manipulate, and/or calculate information to fulfill data and reporting requirements including identifying the tables and columns from which data is extracted.  Responsible for Data modeling and Mapping through data analysis to extract data elements from various OLTP\u2019s using ETL technique and utilized Business Intelligence Tool (Tableu) for report generation. Analyzed and documented the changes in the compliance rules for adverse action redesign. Used Data warehousing for Data Profiling to examine the data available (Data Analysis) in an existing database. Worked in Teradata to make sure completeness of table structures, data and reference table data. Extensive experience in ETL processes in extracting data from Operational and Legacy Systems to Data Warehouse using Informatics. Responsible for providing business requirements within an AGILE software development SCRUM environment.\u00a0 Designed and developed UNIX shell scripts as part of the ETL process to automate the process of loading, pulling the data for testing ETL loads. Ensure day-to-day EDI transmission, Reject tracking and Reconciliation. Run EDI Reconciliation reports daily and document in MS Excel. Maintained and monitored project progress and status through MS Project. Extracted Data from Teradata using Informatica Power Center ETL and DTS Packages to the target database including SQL Server and used the data for Reporting purposes documentations. Used SQL tools like TOAD to run SQL queries to view and validate the data loaded into the warehouse. Designed, Developed and Implemented reports in Qlikview BI Dashboard tool \u2013 one of the most advanced tools for BI and reports. Experience in creating UNIX scripts for file transfer and file manipulation. Worked closely with the Enterprise Data Warehouse team and Business Intelligence. Used the guidelines and artifacts of the Agile Process to strategize the Implementation in different sprints of the Software Development Life Cycle. Performed extensive task which include Data Quality Analysis, Data lineage and Data Standardization data structures, data base design, data warehouses, business. Walk-through the business users: Business Object Reports or QlikView reports. Data mapping, logical data modeling, used SQL queries to filter data within the Oracle and Sybase. Used the Agile methodology to build the different phases of Software development life cycle."}